{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODvNI2LUclE6zcCKe50b6n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lancedsouza/Webscraping_projects/blob/main/FinalCode_for_extractingGemdata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for downloading pdf"
      ],
      "metadata": {
        "id": "-HjjlI5hbgrw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "off3N_CdbEco"
      },
      "outputs": [],
      "source": [
        "# Final Code for downloading pdfs\n",
        "import os\n",
        "import time\n",
        "import io\n",
        "import base64\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "\n",
        "# =============================\n",
        "# CONFIGURATION\n",
        "# =============================\n",
        "DOWNLOAD_DIR = os.path.join(os.getcwd(), \"downloaded_pdfs\")\n",
        "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
        "\n",
        "VIEW_URL = \"https://gem.gov.in/view_contracts\"\n",
        "SEARCH_TERM = \"Hot air gun\"\n",
        "FROM_DATE = \"01-Jan-2024\"  # format: dd-MMM-yyyy\n",
        "\n",
        "# =============================\n",
        "# SELENIUM SETUP\n",
        "# =============================\n",
        "def setup_driver():\n",
        "    chrome_options = Options()\n",
        "    prefs = {\n",
        "        \"download.default_directory\": DOWNLOAD_DIR,\n",
        "        \"download.prompt_for_download\": False,\n",
        "        \"plugins.always_open_pdf_ext\": True\n",
        "    }\n",
        "    chrome_options.add_experimental_option(\"prefs\", prefs)\n",
        "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "    chrome_options.add_argument(\"--start-maximized\")\n",
        "    return webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "\n",
        "def remove_popups(driver):\n",
        "    for pid in (\"gemmy-text-item\", \"flox-text-item\", \"gemmyIcon\"):\n",
        "        driver.execute_script(f\"document.getElementById('{pid}')?.remove();\")\n",
        "\n",
        "\n",
        "def solve_captcha(el):\n",
        "    \"\"\"Capture the captcha image and extract text using OCR.\"\"\"\n",
        "    png = el.screenshot_as_png\n",
        "    img = Image.open(io.BytesIO(png)).convert(\"L\")\n",
        "    return pytesseract.image_to_string(img).strip()\n",
        "\n",
        "\n",
        "def scroll_all_contracts(driver, pause_time=1, stable_limit=7):\n",
        "    \"\"\"Scroll page until all contracts are loaded.\"\"\"\n",
        "    last_count = 0\n",
        "    stable_runs = 0\n",
        "    step_px = 400\n",
        "\n",
        "    while stable_runs < stable_limit:\n",
        "        while True:\n",
        "            scroll_top = driver.execute_script(\"return window.scrollY + window.innerHeight\")\n",
        "            scroll_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "            if scroll_top + 10 >= scroll_height:\n",
        "                break\n",
        "            driver.execute_script(\"window.scrollBy(0, arguments[0]);\", step_px)\n",
        "            time.sleep(pause_time)\n",
        "\n",
        "        elems = driver.find_elements(By.XPATH, \"//a[contains(@onclick,'openCap')]\")\n",
        "        count = len(elems)\n",
        "        print(f\"üîç {count} contracts loaded so far‚Ä¶\")\n",
        "\n",
        "        if count > last_count:\n",
        "            last_count = count\n",
        "            stable_runs = 0\n",
        "        else:\n",
        "            stable_runs += 1\n",
        "            print(f\"‚ö†Ô∏è No new contracts (stable {stable_runs}/{stable_limit})\")\n",
        "\n",
        "        time.sleep(pause_time)\n",
        "\n",
        "    print(f\"‚úÖ Finished scrolling; total contracts found: {last_count}\")\n",
        "    return elems\n",
        "\n",
        "# =============================\n",
        "# MAIN LOGIC\n",
        "# =============================\n",
        "def main():\n",
        "    driver = setup_driver()\n",
        "    wait = WebDriverWait(driver, 20)\n",
        "    processed = set()\n",
        "\n",
        "    try:\n",
        "        driver.get(VIEW_URL)\n",
        "        time.sleep(2)\n",
        "        remove_popups(driver)\n",
        "\n",
        "        # Select category\n",
        "        wait.until(EC.element_to_be_clickable((By.ID, 'select2-buyer_category-container'))).click()\n",
        "        fld = wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'select2-search__field')))\n",
        "        fld.send_keys(SEARCH_TERM + Keys.ENTER)\n",
        "        time.sleep(1)\n",
        "        remove_popups(driver)\n",
        "\n",
        "        # Set from date\n",
        "        d, m, y = FROM_DATE.split('-')\n",
        "        wait.until(EC.element_to_be_clickable((By.ID, 'from_date_contract_search1'))).click()\n",
        "        Select(driver.find_element(By.CLASS_NAME, \"ui-datepicker-month\")).select_by_visible_text(m)\n",
        "        Select(driver.find_element(By.CLASS_NAME, \"ui-datepicker-year\")).select_by_visible_text(y)\n",
        "        wait.until(EC.element_to_be_clickable((By.XPATH, f\"//a[text()='{int(d)}']\"))).click()\n",
        "        time.sleep(1)\n",
        "\n",
        "        # First CAPTCHA\n",
        "        cap1_el = wait.until(EC.presence_of_element_located((By.ID, 'captchaimg1')))\n",
        "        cap1_text = solve_captcha(cap1_el)\n",
        "        driver.find_element(By.ID, 'captcha_code1').send_keys(cap1_text)\n",
        "        wait.until(EC.element_to_be_clickable((By.ID, 'searchlocation1'))).click()\n",
        "        time.sleep(2)\n",
        "\n",
        "        # Load contracts\n",
        "        links = scroll_all_contracts(driver)\n",
        "        onclicks = [el.get_attribute('onclick') for el in links]\n",
        "        print(f\"‚û°Ô∏è Total contracts to process: {len(onclicks)}\")\n",
        "\n",
        "        for idx, js in enumerate(onclicks, 1):\n",
        "            print(f\"‚û°Ô∏è Contract {idx}/{len(onclicks)}\")\n",
        "            if js in processed:\n",
        "                print(\"   ‚è≠ Already processed, skipping.\")\n",
        "                continue\n",
        "\n",
        "            driver.execute_script(js)\n",
        "            time.sleep(1)\n",
        "\n",
        "            try:\n",
        "                cap2_el = wait.until(EC.presence_of_element_located((By.ID, 'captchaimg')))\n",
        "                cap2_text = solve_captcha(cap2_el)\n",
        "                cap_input = wait.until(EC.element_to_be_clickable((By.ID, 'captcha_code')))\n",
        "                cap_input.clear()\n",
        "                cap_input.send_keys(cap2_text)\n",
        "            except Exception as e:\n",
        "                print(\"‚ö†Ô∏è Could not solve CAPTCHA automatically. You can solve it manually now.\")\n",
        "                input(\"üîì Press ENTER after you‚Äôve manually entered CAPTCHA and clicked Submit.\")\n",
        "\n",
        "            # Submit\n",
        "            try:\n",
        "                wait.until(EC.element_to_be_clickable((By.ID, 'modelsbt'))).click()\n",
        "            except:\n",
        "                print(\"‚ö†Ô∏è Submit button not found or clickable.\")\n",
        "\n",
        "            # Pause for manual download\n",
        "            print(\"üßç Waiting for manual CAPTCHA input and download...\")\n",
        "            input(\"üîì After clicking 'Download', press ENTER to continue.\")\n",
        "            print(\"‚úÖ Continuing‚Ä¶\")\n",
        "\n",
        "            processed.add(js)\n",
        "            time.sleep(1)\n",
        "\n",
        "        print(f\"\\nüöÄ Completed. Total contracts processed: {len(processed)}\")\n",
        "\n",
        "    finally:\n",
        "        driver.quit()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for extracting pdf data"
      ],
      "metadata": {
        "id": "OwsesDaAblnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Final Code for extracting data from PDF\n",
        "import os\n",
        "import re\n",
        "import fitz  # PyMuPDF\n",
        "import pandas as pd\n",
        "\n",
        "def normalize_hindi_first(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Swap occurrences where Hindi (Devanagari) appears before English separated by '|',\n",
        "    e.g., \"‡§Ö‡§®‡•Å‡§¨‡§Ç‡§ß|Contract\" ‚Üí \"Contract|‡§Ö‡§®‡•Å‡§¨‡§Ç‡§ß\", so English label is first.\n",
        "    \"\"\"\n",
        "    pattern = re.compile(r'([\\u0900-\\u097F\\s]+)\\|([\\w\\s]+)')\n",
        "    return pattern.sub(r'\\2|\\1', text)\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Clean raw text extracted from PDF:\n",
        "    1. Normalize Hindi-first labels\n",
        "    2. Rejoin split email tokens (remove spaces/newlines after '@')\n",
        "    3. Remove Devanagari characters\n",
        "    4. Replace '|' separators with ' : '\n",
        "    5. Replace control/newline/tab chars with space\n",
        "    6. Remove unwanted special chars except those useful for IDs, emails, numbers\n",
        "    7. Normalize multiple spaces to single space\n",
        "    \"\"\"\n",
        "    # 1. Normalize Hindi-first labels\n",
        "    text = normalize_hindi_first(text)\n",
        "\n",
        "    # 2. Rejoin split email tokens: remove spaces/newlines after '@'\n",
        "    text = re.sub(r'@\\s+', '@', text)\n",
        "\n",
        "    # 3. Remove Devanagari entirely\n",
        "    text = re.sub(r'[\\u0900-\\u097F]', '', text)\n",
        "\n",
        "    # 4. Replace vertical bars '|' with ' : '\n",
        "    text = re.sub(r'\\s*\\|\\s*', ' : ', text)\n",
        "\n",
        "    # 5. Replace control characters/newlines/tabs with space\n",
        "    text = re.sub(r'[\\n\\r\\t\\x0b\\x0c]', ' ', text)\n",
        "\n",
        "    # 6. Remove unwanted special characters but keep those useful for IDs, emails, numbers\n",
        "    #    Allows: word chars (letters/digits/underscore), @ . , : / & ( ) - + % # and whitespace\n",
        "    text = re.sub(r'[^\\w@.,:/&()\\-+%#\\s]', '', text)\n",
        "\n",
        "    # 7. Normalize multiple spaces to single space\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "def extract_text_from_pdf(pdf_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Extract all text from the PDF at pdf_path using PyMuPDF, then clean it.\n",
        "    \"\"\"\n",
        "    text = \"\"\n",
        "    try:\n",
        "        with fitz.open(pdf_path) as doc:\n",
        "            for page in doc:\n",
        "                text += page.get_text()\n",
        "    except Exception as e:\n",
        "        print(f\"Error opening {pdf_path}: {e}\")\n",
        "        return \"\"\n",
        "    cleaned = clean_text(text)\n",
        "    # Debug: inspect a snippet of cleaned text\n",
        "    # print(f\"=== Cleaned text for {os.path.basename(pdf_path)} ===\\n{cleaned[:500]}\\n\")\n",
        "    return cleaned\n",
        "\n",
        "def extract_section(text: str, start_label: str, end_label: str) -> str:\n",
        "    \"\"\"\n",
        "    Extract substring between start_label and next occurrence of end_label.\n",
        "    If end_label is empty or not found, returns everything after start_label.\n",
        "    Matches labels case-insensitively, allows optional colon, strips leading colons/spaces.\n",
        "    \"\"\"\n",
        "    if not start_label or start_label not in text:\n",
        "        return \"\"\n",
        "    if end_label:\n",
        "        pattern = re.compile(\n",
        "            rf\"{re.escape(start_label)}\\s*(?:\\:)?(.*?)(?={re.escape(end_label)}\\s*(?:\\:)?|$)\",\n",
        "            re.IGNORECASE | re.DOTALL\n",
        "        )\n",
        "    else:\n",
        "        pattern = re.compile(\n",
        "            rf\"{re.escape(start_label)}\\s*(?:\\:)?(.*)$\",\n",
        "            re.IGNORECASE | re.DOTALL\n",
        "        )\n",
        "    m = pattern.search(text)\n",
        "    if not m:\n",
        "        return \"\"\n",
        "    sec = m.group(1).strip()\n",
        "    sec = sec.lstrip(\": \").strip()\n",
        "    # Debug: inspect the isolated section\n",
        "    # print(f\"=== Section '{start_label}' content ===\\n{sec[:300]}\\n\")\n",
        "    return sec\n",
        "\n",
        "def extract_buyer(section: str) -> dict:\n",
        "    \"\"\"\n",
        "    Extract fields from Buyer Details section, using flexible patterns:\n",
        "    - buyer_designation\n",
        "    - buyer_contact_no\n",
        "    - buyer_email\n",
        "    - buyer_gstin\n",
        "    - buyer_address\n",
        "    \"\"\"\n",
        "    fields = {\n",
        "        \"buyer_designation\": None,\n",
        "        \"buyer_contact_no\": None,\n",
        "        \"buyer_email\": None,\n",
        "        \"buyer_gstin\": None,\n",
        "        \"buyer_address\": None\n",
        "    }\n",
        "    if not section:\n",
        "        return fields\n",
        "    section = section.lstrip(\": \").strip()\n",
        "\n",
        "    # DESIGNATION: up to next Contact No or Email ID\n",
        "    m = re.search(r\"Designation\\b.*?:\\s*(.+?)(?=(Contact\\s*No\\b|Email\\s*ID\\b|$))\",\n",
        "                  section, re.IGNORECASE)\n",
        "    if m:\n",
        "        val = m.group(1).strip().rstrip(\":\").strip()\n",
        "        fields[\"buyer_designation\"] = val or None\n",
        "\n",
        "    # CONTACT NO: look for first sequence of digits/hyphens after \"Contact No\"\n",
        "    m = re.search(r\"Contact\\s*No\\b.*?([0-9][0-9\\-\\s]+)\", section, re.IGNORECASE)\n",
        "    if m:\n",
        "        val = m.group(1).strip().rstrip(\"- \").strip()\n",
        "        fields[\"buyer_contact_no\"] = val or None\n",
        "\n",
        "    # EMAIL ID: look for email pattern after \"Email ID\"\n",
        "    m = re.search(\n",
        "        r\"Email\\s*ID\\b.*?([A-Za-z0-9._%+\\-]+@[A-Za-z0-9.\\-]+\\.[A-Za-z]{2,})\",\n",
        "        section, re.IGNORECASE\n",
        "    )\n",
        "    if m:\n",
        "        email = m.group(1).strip().rstrip(\"_ \").strip()\n",
        "        fields[\"buyer_email\"] = email or None\n",
        "\n",
        "    # GSTIN: strict 15-character GSTIN pattern: 2 digits then 13 alphanumeric\n",
        "    # Example pattern: r\"\\b[0-9]{2}[A-Z0-9]{13}\\b\"\n",
        "    m = re.search(r\"GSTIN\\b.*?\\b([0-9]{2}[A-Za-z0-9]{13})\\b\", section, re.IGNORECASE)\n",
        "    if m:\n",
        "        val = m.group(1).strip().upper()\n",
        "        fields[\"buyer_gstin\"] = val or None\n",
        "\n",
        "    # ADDRESS: until next known label or end\n",
        "    m = re.search(\n",
        "        r\"Address\\b.*?:(.*?)(?=(Financial Approval Detail\\b|Paying Authority Details\\b|$))\",\n",
        "        section, re.IGNORECASE | re.DOTALL\n",
        "    )\n",
        "    if m:\n",
        "        addr = re.sub(r'\\s+', ' ', m.group(1)).strip()\n",
        "        fields[\"buyer_address\"] = addr or None\n",
        "\n",
        "    return fields\n",
        "\n",
        "def extract_seller(section: str) -> dict:\n",
        "    \"\"\"\n",
        "    Extract fields from Seller Details section, using flexible patterns:\n",
        "    - seller_id\n",
        "    - seller_name\n",
        "    - seller_contact\n",
        "    - seller_email\n",
        "    - seller_gstin\n",
        "    - seller_address\n",
        "    \"\"\"\n",
        "    fields = {\n",
        "        \"seller_id\": None,\n",
        "        \"seller_name\": None,\n",
        "        \"seller_contact\": None,\n",
        "        \"seller_email\": None,\n",
        "        \"seller_gstin\": None,\n",
        "        \"seller_address\": None\n",
        "    }\n",
        "    if not section:\n",
        "        return fields\n",
        "    section = section.lstrip(\": \").strip()\n",
        "\n",
        "    # GeM Seller ID\n",
        "    m = re.search(r\"GeM Seller ID\\b.*?(\\S+)\", section, re.IGNORECASE)\n",
        "    if m:\n",
        "        fields[\"seller_id\"] = m.group(1).strip()\n",
        "\n",
        "    # Company Name\n",
        "    m = re.search(r\"Company Name\\b.*?:\\s*(.+?)(?=(Contact\\s*No\\b|Email\\s*ID\\b|$))\",\n",
        "                  section, re.IGNORECASE)\n",
        "    if m:\n",
        "        val = m.group(1).strip().rstrip(\":\").strip()\n",
        "        fields[\"seller_name\"] = val or None\n",
        "\n",
        "    # Contact No\n",
        "    m = re.search(r\"Contact\\s*No\\b.*?([0-9][0-9\\-\\s]+)\", section, re.IGNORECASE)\n",
        "    if m:\n",
        "        val = m.group(1).strip().rstrip(\"- \").strip()\n",
        "        fields[\"seller_contact\"] = val or None\n",
        "\n",
        "    # Email ID\n",
        "    m = re.search(\n",
        "        r\"Email\\s*ID\\b.*?([A-Za-z0-9._%+\\-]+@[A-Za-z0-9.\\-]+\\.[A-Za-z]{2,})\",\n",
        "        section, re.IGNORECASE\n",
        "    )\n",
        "    if m:\n",
        "        email = m.group(1).strip().rstrip(\"_ \").strip()\n",
        "        fields[\"seller_email\"] = email or None\n",
        "\n",
        "    # GSTIN: strict 15-character pattern\n",
        "    m = re.search(r\"GSTIN\\b.*?\\b([0-9]{2}[A-Za-z0-9]{13})\\b\", section, re.IGNORECASE)\n",
        "    if m:\n",
        "        val = m.group(1).strip().upper()\n",
        "        fields[\"seller_gstin\"] = val or None\n",
        "\n",
        "    # Address\n",
        "    m = re.search(r\"Address\\b.*?:(.*?)(?=(MSME Registration\\b|GST/TAX\\b|$))\",\n",
        "                  section, re.IGNORECASE | re.DOTALL)\n",
        "    if m:\n",
        "        addr = re.sub(r'\\s+', ' ', m.group(1)).strip()\n",
        "        fields[\"seller_address\"] = addr or None\n",
        "\n",
        "    return fields\n",
        "\n",
        "def extract_product(section: str) -> dict:\n",
        "    \"\"\"\n",
        "    Extract product-related fields; unchanged from previous patterns.\n",
        "    \"\"\"\n",
        "    fields = {\n",
        "        \"product_name\": None,\n",
        "        \"product_brand\": None,\n",
        "        \"product_category\": None,\n",
        "        \"product_model\": None,\n",
        "        \"ordered_quantity\": None,\n",
        "        \"unit\": None,\n",
        "        \"unit_price\": None,\n",
        "        \"tax_bifurcation\": None,\n",
        "        \"price_inclusive\": None,\n",
        "        \"total_order_value\": None\n",
        "    }\n",
        "    if not section:\n",
        "        return fields\n",
        "\n",
        "    # Product Name\n",
        "    m = re.search(r\"Product Name\\b.*?:\\s*(.+?)(?=\\s*Brand\\b)\", section, re.IGNORECASE)\n",
        "    if m:\n",
        "        fields[\"product_name\"] = m.group(1).strip()\n",
        "\n",
        "    # Brand\n",
        "    m = re.search(r\"Brand\\b.*?:\\s*(.+?)(?=\\s*Brand Type\\b)\", section, re.IGNORECASE)\n",
        "    if m:\n",
        "        fields[\"product_brand\"] = m.group(1).strip()\n",
        "\n",
        "    # Category\n",
        "    m = re.search(r\"Category Name & Quadrant\\b.*?:\\s*(.+?)(?=\\s*Model\\b)\", section, re.IGNORECASE)\n",
        "    if m:\n",
        "        fields[\"product_category\"] = m.group(1).strip()\n",
        "\n",
        "    # Model\n",
        "    m = re.search(r\"Model\\b.*?:\\s*(.+?)(?=\\s*HSN Code\\b)\", section, re.IGNORECASE)\n",
        "    if m:\n",
        "        fields[\"product_model\"] = m.group(1).strip()\n",
        "\n",
        "    # After HSN Code: ordered_quantity, unit, unit_price, tax_bifurcation, price_inclusive\n",
        "    m = re.search(\n",
        "        r\"HSN Code\\b.*?([\\d,]+)\\s+(\\w+)\\s+([\\d,]+)\\s+([A-Za-z0-9]+)\\s+([\\d,]+)\",\n",
        "        section, re.IGNORECASE\n",
        "    )\n",
        "    if m:\n",
        "        fields[\"ordered_quantity\"] = m.group(1).strip()\n",
        "        fields[\"unit\"] = m.group(2).strip()\n",
        "        fields[\"unit_price\"] = m.group(3).strip()\n",
        "        fields[\"tax_bifurcation\"] = m.group(4).strip()\n",
        "        fields[\"price_inclusive\"] = m.group(5).strip()\n",
        "\n",
        "    # Total Order Value\n",
        "    m = re.search(r\"Total Order Value\\b.*?\\(?in INR\\)?\\s*:\\s*([\\d,]+)\", section, re.IGNORECASE)\n",
        "    if m:\n",
        "        fields[\"total_order_value\"] = m.group(1).strip()\n",
        "\n",
        "    return fields\n",
        "\n",
        "def process_folder(pdf_dir: str, output_excel: str):\n",
        "    \"\"\"\n",
        "    Iterate over PDFs in pdf_dir, extract fields, and save to Excel.\n",
        "    \"\"\"\n",
        "    all_rows = []\n",
        "    for fname in os.listdir(pdf_dir):\n",
        "        if not fname.lower().endswith(\".pdf\"):\n",
        "            continue\n",
        "        path = os.path.join(pdf_dir, fname)\n",
        "        text = extract_text_from_pdf(path)\n",
        "        if not text:\n",
        "            continue\n",
        "\n",
        "        buyer_sec = extract_section(text, \"Buyer Details\", \"Seller Details\")\n",
        "        seller_sec = extract_section(text, \"Seller Details\", \"Product Details\")\n",
        "        product_sec = extract_section(text, \"Product Details\", \"\")\n",
        "\n",
        "        # Debug: inspect sections if needed\n",
        "        # print(f\"--- {fname} Buyer Section ---\\n{buyer_sec}\\n\")\n",
        "        # print(f\"--- {fname} Seller Section ---\\n{seller_sec}\\n\")\n",
        "\n",
        "        row = {\"filename\": fname}\n",
        "        row.update(extract_buyer(buyer_sec))\n",
        "        row.update(extract_seller(seller_sec))\n",
        "        row.update(extract_product(product_sec))\n",
        "        all_rows.append(row)\n",
        "\n",
        "    if not all_rows:\n",
        "        print(\"No PDFs found or no data extracted in folder:\", pdf_dir)\n",
        "        return\n",
        "    df = pd.DataFrame(all_rows)\n",
        "    try:\n",
        "        df.to_excel(output_excel, index=False)\n",
        "        print(f\"Saved extracted data to {output_excel}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving to Excel {output_excel}: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Adjust pdf_folder path as needed\n",
        "    pdf_folder = r\"C:\\Users\\Wishes Lawrence\\downloaded_pdfs\"\n",
        "    output_file = os.path.join(pdf_folder, \"extracted_contracts1_hotairgun.xlsx\")\n",
        "    process_folder(pdf_folder, output_file)\n"
      ],
      "metadata": {
        "id": "u8trcAcvbxg8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}