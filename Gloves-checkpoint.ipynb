{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79a2cafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# from selenium.common.exceptions import StaleElementReferenceException, ElementClickInterceptedException\n",
    "# import time\n",
    "# import pandas as pd\n",
    "# from selenium.webdriver import ActionChains, Keys\n",
    "# website= 'https://www.amazon.com/s?k=Industrial+Gloves&i=tools&rh=n%3A228013&dc&language=en_US&currency=INR&qid=1735030645&rnid=24039780011&xpid=x3K9M7iwPmCm6&ref=sr_nr_p_n_feature_twelve_browse-bin_19&ds=v1%3ALl2lWD4gcrBBx87mclRNheuGChA%2BHDLYrWuYtImJcH8'\n",
    "# path = 'C:\\\\Users\\\\Wishes Lawrence\\\\Documents\\\\Chromedriver\\\\chromedriver-win64\\\\chromedriver.exe'\n",
    "# chrome_options=Options()\n",
    "# chrome_options.add_argument(\"--disable-notifications\")\n",
    "# driver=webdriver.Chrome(options=chrome_options)\n",
    "# driver.maximize_window()\n",
    "# driver.get(website)\n",
    "# time.sleep(10)\n",
    "# from selenium.webdriver.common.by import By\n",
    "\n",
    "# driver.get(website)\n",
    "\n",
    "\n",
    "# # Open the website\n",
    "# # driver.get(website)\n",
    "# # time.sleep(10)\n",
    "\n",
    "\n",
    "# # Wait for the webpage to load\n",
    "# driver.implicitly_wait(5)\n",
    "\n",
    "# # Lists to store extracted data\n",
    "# product_name = []\n",
    "# product_price = []\n",
    "# price_no_offers=[]\n",
    "# product_ratings = []\n",
    "# product_ratings_num = []\n",
    "# product_bought = []\n",
    "# # pagination\n",
    "# pagination=driver.find_elements(By.XPATH,'//span[contains(@class,\"s-pagination-strip\")]')\n",
    "                                  \n",
    "# pages=driver.find_elements(By.XPATH,'.//span/a[contains(@class,\"s-pagination-item s-pagination-button\")]')\n",
    "# print(pages)\n",
    "\n",
    "# last_page=4\n",
    "\n",
    "\n",
    "\n",
    "# current_page=1\n",
    "# print(f'\"current_page:\"{current_page}')\n",
    "\n",
    "# while current_page<=last_page:\n",
    "#     # Scroll to the bottom of the page to load more items\n",
    "#     items = WebDriverWait(driver, 20).until(EC.presence_of_all_elements_located((By.XPATH, '//div/div/span[@class=\"rush-component s-latency-cf-section\"]')))\n",
    "#     print(items)\n",
    "    \n",
    "#     for item in items:\n",
    "#         try:\n",
    "#             name = item.find_element(By.XPATH, './/div[contains(@data-cy, \"title-recipe\")]').text\n",
    "#             product_name.append(name)\n",
    "#             print(name)\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             product_name.append(\"N/A\")\n",
    "        \n",
    "#         try:\n",
    "#             price = item.find_element(By.XPATH, './/span[@class=\"a-price-whole\"]').text\n",
    "#             product_price.append(price)\n",
    "#         except Exception as e:\n",
    "#             product_price.append(\"N/A\")\n",
    "\n",
    "#             price_no_offer=item.find_element(By.XPATH, './/div/span[@class=\"a-color-base\"]').text\n",
    "#             price_no_offers.append(price_no_offer)\n",
    "\n",
    "#         try:\n",
    "#             ratings = item.find_element(By.XPATH,'.//i[contains(@data-cy,\"reviews-ratings-slot\")]').text\n",
    "#             product_ratings.append(ratings)\n",
    "#             print(ratings)\n",
    "#         except Exception as e:\n",
    "#             product_ratings.append(\"N/A\")\n",
    "\n",
    "#         try:\n",
    "#             ratings_num = item.find_element(By.XPATH, './/span[@class=\"a-size-base s-underline-text\"]').text\n",
    "#             product_ratings_num.append(ratings_num)\n",
    "#             print(ratings_num)\n",
    "#         except Exception as e:\n",
    "#             product_ratings_num.append(\"N/A\")\n",
    "\n",
    "#         try:\n",
    "#             how_many_bought = item.find_element(By.XPATH, './/span[@class=\"a-size-base a-color-secondary\"]').text\n",
    "#             product_bought.append(how_many_bought)\n",
    "#             print(how_many_bought)\n",
    "#         except Exception as e:\n",
    "#             product_bought.append(\"N/A\")\n",
    "\n",
    "# #         try:\n",
    "# #             link = item.find_element(By.XPATH, './/h2/a').get_attribute(\"href\")\n",
    "# #             product_link.append(link)\n",
    "# #         except Exception as e:\n",
    "# #             product_link.append(\"N/A\")\n",
    "\n",
    "#     print(f\"Page {current_page} scraped. Extracted {len(items)} items.\")\n",
    "#     current_page += 1\n",
    "\n",
    "#     # # Attempt to click the \"Next\" page button with a corrected XPath (removed extra space)\n",
    "#     # try:\n",
    "#     #     next_button = WebDriverWait(driver, 10).until(\n",
    "#     #     EC.element_to_be_clickable((By.XPATH, '//a[contains(@aria-label, \"Next\")]'))\n",
    "#     # )\n",
    "#     #     next_button.click()\n",
    "#     #     time.sleep(5)\n",
    "#     # except Exception as e:\n",
    "#     #     print(f\"Could not navigate to next page: {e}\")\n",
    "\n",
    "\n",
    "# # Creating DataFrame\n",
    "# df = pd.DataFrame({\n",
    "#     'product_name': product_name,\n",
    "#     'product_price': product_price,\n",
    "#     'product_ratings': product_ratings,\n",
    "#     'product_ratings_num': product_ratings_num,    \n",
    "#     'product_bought': product_bought\n",
    "    \n",
    "# })\n",
    "\n",
    "\n",
    "# # Debugging: Print lengths of lists\n",
    "# print(f\"Lengths: Names={len(product_name)}, Prices={len(product_price)}, Ratings={len(product_ratings)},price_nooffers{price_no_offers} \"\n",
    "#       f\"Ratings Num={len(product_ratings_num)},  Bought={len(product_bought)}\")\n",
    "\n",
    "# print(df)\n",
    "# df.to_excel('amazon_gloves.xlsx', index=False)\n",
    "# # Close the WebDriver\n",
    "# driver.quit()\n",
    "\n",
    "# # Close the WebDriver\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d03a0a4-b3ba-4fbb-ae4a-908859dc8d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon.com : Industrial Gloves\n",
      "Page 1 scraped. Extracted 43 items.\n",
      "Page 2 scraped. Extracted 40 items.\n",
      "Page 3 scraped. Extracted 41 items.\n",
      "Page 4 scraped. Extracted 44 items.\n",
      "Page 5 scraped. Extracted 44 items.\n",
      "Page 6 scraped. Extracted 43 items.\n",
      "Page 7 scraped. Extracted 44 items.\n",
      "Page 8 scraped. Extracted 43 items.\n",
      "Page 9 scraped. Extracted 43 items.\n",
      "Page 10 scraped. Extracted 41 items.\n",
      "Page 11 scraped. Extracted 44 items.\n",
      "Page 12 scraped. Extracted 41 items.\n",
      "Page 13 scraped. Extracted 43 items.\n",
      "Page 14 scraped. Extracted 41 items.\n",
      "Page 15 scraped. Extracted 43 items.\n",
      "Page 16 scraped. Extracted 41 items.\n",
      "Page 17 scraped. Extracted 41 items.\n",
      "Page 18 scraped. Extracted 43 items.\n",
      "Page 19 scraped. Extracted 43 items.\n",
      "Page 20 scraped. Extracted 41 items.\n",
      "Page 21 scraped. Extracted 44 items.\n",
      "Page 22 scraped. Extracted 43 items.\n",
      "Page 23 scraped. Extracted 43 items.\n",
      "Page 24 scraped. Extracted 43 items.\n",
      "Page 25 scraped. Extracted 43 items.\n",
      "Page 26 scraped. Extracted 44 items.\n",
      "Page 27 scraped. Extracted 44 items.\n",
      "Page 28 scraped. Extracted 43 items.\n",
      "Page 29 scraped. Extracted 44 items.\n",
      "Page 30 scraped. Extracted 44 items.\n",
      "Page 31 scraped. Extracted 43 items.\n",
      "Page 32 scraped. Extracted 43 items.\n",
      "Page 33 scraped. Extracted 43 items.\n",
      "Page 34 scraped. Extracted 44 items.\n",
      "Page 35 scraped. Extracted 44 items.\n",
      "Page 36 scraped. Extracted 43 items.\n",
      "Page 37 scraped. Extracted 44 items.\n",
      "Page 38 scraped. Extracted 44 items.\n",
      "Page 39 scraped. Extracted 43 items.\n",
      "Page 40 scraped. Extracted 43 items.\n",
      "Scraping completed and data saved.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import StaleElementReferenceException, TimeoutException, NoSuchElementException\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Setup Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-notifications\")\n",
    "chrome_options.add_argument(\"--start-maximized\")\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "# Initialize WebDriver\n",
    "website = 'https://www.amazon.com/s?k=Industrial+Gloves&i=tools&rh=n%3A228013&dc&language=en_US&currency=INR&qid=1735030645&rnid=24039780011'\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.get(website)\n",
    "\n",
    "# Give time to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Check if page opened successfully\n",
    "print(driver.title)\n",
    "\n",
    "# Lists to store extracted data\n",
    "product_name = []\n",
    "product_price = []\n",
    "price_no_offers = []\n",
    "product_ratings = []\n",
    "product_ratings_num = []\n",
    "product_bought = []\n",
    "\n",
    "# Number of pages to scrape\n",
    "last_page = 55\n",
    "current_page = 1\n",
    "\n",
    "while current_page <= last_page:\n",
    "    try:\n",
    "        # Wait for the items to load\n",
    "        items = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, './/div[contains(@class,\"s-main-slot\")]/div'))\n",
    "        )\n",
    "\n",
    "        for item in items:\n",
    "            try:\n",
    "                name = item.find_element(By.XPATH, './/div[contains(@data-cy, \"title-recipe\")]').text\n",
    "                product_name.append(name)\n",
    "            except NoSuchElementException:\n",
    "                product_name.append(\"N/A\")\n",
    "\n",
    "            try:\n",
    "                price = item.find_element(By.XPATH, './/span[@class=\"a-price-whole\"]').text\n",
    "                product_price.append(price)\n",
    "            except NoSuchElementException:\n",
    "                product_price.append(\"N/A\")\n",
    "\n",
    "            try:\n",
    "                price_no_offer = item.find_element(By.XPATH, './/span[@class=\"a-color-base\"]').text\n",
    "                price_no_offers.append(price_no_offer)\n",
    "            except NoSuchElementException:\n",
    "                price_no_offers.append(\"N/A\")\n",
    "\n",
    "            try:\n",
    "                ratings = item.find_element(By.XPATH, './/span[@class=\"a-icon-alt\"]').text\n",
    "                product_ratings.append(ratings)\n",
    "            except NoSuchElementException:\n",
    "                product_ratings.append(\"N/A\")\n",
    "\n",
    "            try:\n",
    "                ratings_num = item.find_element(By.XPATH, './/span[@class=\"a-size-base s-underline-text\"]').text\n",
    "                product_ratings_num.append(ratings_num)\n",
    "            except NoSuchElementException:\n",
    "                product_ratings_num.append(\"N/A\")\n",
    "\n",
    "            try:\n",
    "                how_many_bought = item.find_element(By.XPATH, './/span[contains(text(),\"bought\") or contains(text(),\"sold\")]').text\n",
    "                product_bought.append(how_many_bought)\n",
    "            except NoSuchElementException:\n",
    "                product_bought.append(\"N/A\")\n",
    "\n",
    "        print(f\"Page {current_page} scraped. Extracted {len(items)} items.\")\n",
    "\n",
    "        # Click \"Next\" button if available\n",
    "        try:\n",
    "            next_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, '//a[contains(@class, \"s-pagination-next\")]'))\n",
    "            )\n",
    "            next_button.click()\n",
    "            time.sleep(3)\n",
    "        except (TimeoutException, NoSuchElementException):\n",
    "            print(\"No more pages found or failed to click Next.\")\n",
    "            break\n",
    "\n",
    "        current_page += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error on page {current_page}: {e}\")\n",
    "        break\n",
    "\n",
    "# Creating DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'product_name': product_name,\n",
    "    'product_price': product_price,\n",
    "    'price_no_offers': price_no_offers,\n",
    "    'product_ratings': product_ratings,\n",
    "    'product_ratings_num': product_ratings_num,\n",
    "    'product_bought': product_bought\n",
    "})\n",
    "\n",
    "# Save to Excel\n",
    "df.to_excel('amazon_gloves.xlsx', index=False)\n",
    "\n",
    "# Close WebDriver\n",
    "driver.quit()\n",
    "\n",
    "print(\"Scraping completed and data saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24fd7de0-13ea-4de9-b8df-ce2af0031652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# from selenium.common.exceptions import StaleElementReferenceException, TimeoutException, NoSuchElementException\n",
    "# import pandas as pd\n",
    "# import time\n",
    "\n",
    "# # Setup Chrome options\n",
    "# chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--disable-notifications\")\n",
    "# chrome_options.add_argument(\"--start-maximized\")\n",
    "# chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "# # Initialize WebDriver\n",
    "# website = 'https://www.amazon.com/s?k=Industrial+Gloves&i=tools&rh=n%3A228013&dc&language=en_US&currency=INR&qid=1735030645&rnid=24039780011'\n",
    "# driver = webdriver.Chrome(options=chrome_options)\n",
    "# driver.get(website)\n",
    "\n",
    "# # Give time to load\n",
    "# time.sleep(5)\n",
    "\n",
    "# # Check if page opened successfully\n",
    "# print(f\"Scraping started: {driver.title}\")\n",
    "\n",
    "# # Lists to store extracted data\n",
    "# product_name = []\n",
    "# product_price = []\n",
    "# price_no_offers = []\n",
    "# product_ratings = []\n",
    "# product_ratings_num = []\n",
    "# product_bought = []\n",
    "\n",
    "# # Pagination loop\n",
    "# page_number = 1\n",
    "\n",
    "# while True:\n",
    "#     try:\n",
    "#         print(f\"Scraping page {page_number}: {driver.current_url}\")\n",
    "\n",
    "#         # Wait for the items to load\n",
    "#         items = WebDriverWait(driver, 10).until(\n",
    "#             EC.presence_of_all_elements_located((By.XPATH, './/div[contains(@class,\"s-main-slot\")]/div'))\n",
    "#         )\n",
    "\n",
    "#         for item in items:\n",
    "#             try:\n",
    "#                 name = item.find_element(By.XPATH, './/div[contains(@data-cy, \"title-recipe\")]').text\n",
    "#                 product_name.append(name)\n",
    "#             except NoSuchElementException:\n",
    "#                 product_name.append(\"N/A\")\n",
    "\n",
    "#             try:\n",
    "#                 price = item.find_element(By.XPATH, './/span[@class=\"a-price-whole\"]').text\n",
    "#                 product_price.append(price)\n",
    "#             except NoSuchElementException:\n",
    "#                 product_price.append(\"N/A\")\n",
    "\n",
    "#             try:\n",
    "#                 price_no_offer = item.find_element(By.XPATH, './/span[@class=\"a-color-base\"]').text\n",
    "#                 price_no_offers.append(price_no_offer)\n",
    "#             except NoSuchElementException:\n",
    "#                 price_no_offers.append(\"N/A\")\n",
    "\n",
    "#             try:\n",
    "#                 ratings = item.find_element(By.XPATH, './/span[@class=\"a-icon-alt\"]').text\n",
    "#                 product_ratings.append(ratings)\n",
    "#             except NoSuchElementException:\n",
    "#                 product_ratings.append(\"N/A\")\n",
    "\n",
    "#             try:\n",
    "#                 ratings_num = item.find_element(By.XPATH, './/span[@class=\"a-size-base s-underline-text\"]').text\n",
    "#                 product_ratings_num.append(ratings_num)\n",
    "#             except NoSuchElementException:\n",
    "#                 product_ratings_num.append(\"N/A\")\n",
    "\n",
    "#             try:\n",
    "#                 how_many_bought = item.find_element(By.XPATH, './/span[contains(text(),\"bought\") or contains(text(),\"sold\")]').text\n",
    "#                 product_bought.append(how_many_bought)\n",
    "#             except NoSuchElementException:\n",
    "#                 product_bought.append(\"N/A\")\n",
    "\n",
    "#         print(f\"Page {page_number} scraped. Extracted {len(items)} items.\")\n",
    "\n",
    "#         # Check for \"Next\" button\n",
    "#         try:\n",
    "#             next_button = WebDriverWait(driver, 10).until(\n",
    "#                 EC.element_to_be_clickable((By.XPATH, '//a[contains(@class, \"s-pagination-next\")]'))\n",
    "#             )\n",
    "#             next_button.click()\n",
    "#             page_number += 1\n",
    "#             time.sleep(5)  # Allow time for next page to load\n",
    "#         except (TimeoutException, NoSuchElementException):\n",
    "#             print(\"No more pages found or failed to click Next.\")\n",
    "#             break\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error on page {page_number}: {e}\")\n",
    "#         break\n",
    "\n",
    "# # Creating DataFrame\n",
    "# df = pd.DataFrame({\n",
    "#     'product_name': product_name,\n",
    "#     'product_price': product_price,\n",
    "#     'price_no_offers': price_no_offers,\n",
    "#     'product_ratings': product_ratings,\n",
    "#     'product_ratings_num': product_ratings_num,\n",
    "#     'product_bought': product_bought\n",
    "# })\n",
    "\n",
    "# # Save to Excel\n",
    "# df.to_excel('amazon_gloves.xlsx', index=False)\n",
    "\n",
    "# # Close WebDriver\n",
    "# driver.quit()\n",
    "\n",
    "# print(\"Scraping completed and data saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23bacb9a-692f-4620-9fa7-41b622dcdc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping started: Amazon.in : industrial gloves\n",
      "Scraping page 1: https://www.amazon.in/s?k=industrial+gloves&i=industrial&rh=n%3A5866078031%2Cp_n_feature_browse-bin%3A29591503031%257C29591523031&dc&ds=v1%3AVxikSOEHytC6LBNN3kB7BkNR8Yz9sf7tUHWxDqvsMF0&crid=TOWUBXV7K99X&qid=1739436234&rnid=29590822031&sprefix=%2Caps%2C488&ref=sr_nr_p_n_feature_browse-bin_3\n",
      "Page 1 scraped. Extracted 45 items.\n",
      "Scraping page 2: https://www.amazon.in/s?k=industrial+gloves&i=industrial&rh=n%3A5866078031%2Cp_n_feature_browse-bin%3A29591503031%257C29591523031&dc&page=2&xpid=qldnkxR_MsfSR&crid=TOWUBXV7K99X&qid=1739436519&rnid=29590822031&sprefix=%2Caps%2C488&ref=sr_pg_1\n",
      "Page 2 scraped. Extracted 45 items.\n",
      "Scraping page 3: https://www.amazon.in/s?k=industrial+gloves&i=industrial&rh=n%3A5866078031%2Cp_n_feature_browse-bin%3A29591503031%257C29591523031&dc&page=3&crid=TOWUBXV7K99X&qid=1739436544&rnid=29590822031&sprefix=%2Caps%2C488&xpid=qldnkxR_MsfSR&ref=sr_pg_2\n",
      "Page 3 scraped. Extracted 44 items.\n",
      "Scraping page 4: https://www.amazon.in/s?k=industrial+gloves&i=industrial&rh=n%3A5866078031%2Cp_n_feature_browse-bin%3A29591503031%257C29591523031&dc&page=4&crid=TOWUBXV7K99X&qid=1739436558&rnid=29590822031&sprefix=%2Caps%2C488&xpid=qldnkxR_MsfSR&ref=sr_pg_3\n",
      "Page 4 scraped. Extracted 42 items.\n",
      "Scraping page 5: https://www.amazon.in/s?k=industrial+gloves&i=industrial&rh=n%3A5866078031%2Cp_n_feature_browse-bin%3A29591503031%257C29591523031&dc&page=5&crid=TOWUBXV7K99X&qid=1739436573&rnid=29590822031&sprefix=%2Caps%2C488&xpid=qldnkxR_MsfSR&ref=sr_pg_4\n",
      "Page 5 scraped. Extracted 44 items.\n",
      "Scraping page 6: https://www.amazon.in/s?k=industrial+gloves&i=industrial&rh=n%3A5866078031%2Cp_n_feature_browse-bin%3A29591503031%257C29591523031&dc&page=6&crid=TOWUBXV7K99X&qid=1739436590&rnid=29590822031&sprefix=%2Caps%2C488&xpid=qldnkxR_MsfSR&ref=sr_pg_5\n",
      "Page 6 scraped. Extracted 42 items.\n",
      "Scraping page 7: https://www.amazon.in/s?k=industrial+gloves&i=industrial&rh=n%3A5866078031%2Cp_n_feature_browse-bin%3A29591503031%257C29591523031&dc&page=7&crid=TOWUBXV7K99X&qid=1739436607&rnid=29590822031&sprefix=%2Caps%2C488&xpid=qldnkxR_MsfSR&ref=sr_pg_6\n",
      "Page 7 scraped. Extracted 41 items.\n",
      "Scraping page 8: https://www.amazon.in/s?k=industrial+gloves&i=industrial&rh=n%3A5866078031%2Cp_n_feature_browse-bin%3A29591503031%257C29591523031&dc&page=8&crid=TOWUBXV7K99X&qid=1739436623&rnid=29590822031&sprefix=%2Caps%2C488&xpid=qldnkxR_MsfSR&ref=sr_pg_7\n",
      "Page 8 scraped. Extracted 39 items.\n",
      "Scraping page 9: https://www.amazon.in/s?k=industrial+gloves&i=industrial&rh=n%3A5866078031%2Cp_n_feature_browse-bin%3A29591503031%257C29591523031&dc&page=9&crid=TOWUBXV7K99X&qid=1739436639&rnid=29590822031&sprefix=%2Caps%2C488&xpid=qldnkxR_MsfSR&ref=sr_pg_8\n",
      "Page 9 scraped. Extracted 41 items.\n",
      "Scraping page 10: https://www.amazon.in/s?k=industrial+gloves&i=industrial&rh=n%3A5866078031%2Cp_n_feature_browse-bin%3A29591503031%257C29591523031&dc&page=10&crid=TOWUBXV7K99X&qid=1739436660&rnid=29590822031&sprefix=%2Caps%2C488&xpid=qldnkxR_MsfSR&ref=sr_pg_9\n",
      "Page 10 scraped. Extracted 41 items.\n",
      "Scraping page 11: https://www.amazon.in/s?k=industrial+gloves&i=industrial&rh=n%3A5866078031%2Cp_n_feature_browse-bin%3A29591503031%257C29591523031&dc&page=11&crid=TOWUBXV7K99X&qid=1739436688&rnid=29590822031&sprefix=%2Caps%2C488&xpid=qldnkxR_MsfSR&ref=sr_pg_10\n",
      "Page 11 scraped. Extracted 41 items.\n",
      "Scraping page 12: https://www.amazon.in/s?k=industrial+gloves&i=industrial&rh=n%3A5866078031%2Cp_n_feature_browse-bin%3A29591503031%257C29591523031&dc&page=12&crid=TOWUBXV7K99X&qid=1739436708&rnid=29590822031&sprefix=%2Caps%2C488&xpid=qldnkxR_MsfSR&ref=sr_pg_11\n",
      "Page 12 scraped. Extracted 39 items.\n",
      "Scraping page 13: https://www.amazon.in/s?k=industrial+gloves&i=industrial&rh=n%3A5866078031%2Cp_n_feature_browse-bin%3A29591503031%257C29591523031&dc&page=13&crid=TOWUBXV7K99X&qid=1739436731&rnid=29590822031&sprefix=%2Caps%2C488&xpid=qldnkxR_MsfSR&ref=sr_pg_12\n",
      "Page 13 scraped. Extracted 41 items.\n",
      "Scraping page 14: https://www.amazon.in/s?k=industrial+gloves&i=industrial&rh=n%3A5866078031%2Cp_n_feature_browse-bin%3A29591503031%257C29591523031&dc&page=14&crid=TOWUBXV7K99X&qid=1739436751&rnid=29590822031&sprefix=%2Caps%2C488&xpid=qldnkxR_MsfSR&ref=sr_pg_13\n",
      "Page 14 scraped. Extracted 41 items.\n",
      "Scraping page 15: https://www.amazon.in/s?k=industrial+gloves&i=industrial&rh=n%3A5866078031%2Cp_n_feature_browse-bin%3A29591503031%257C29591523031&dc&page=15&crid=TOWUBXV7K99X&qid=1739436773&rnid=29590822031&sprefix=%2Caps%2C488&xpid=qldnkxR_MsfSR&ref=sr_pg_14\n",
      "Page 15 scraped. Extracted 41 items.\n",
      "Scraping page 16: https://www.amazon.in/s?k=industrial+gloves&i=industrial&rh=n%3A5866078031%2Cp_n_feature_browse-bin%3A29591503031%257C29591523031&dc&page=16&crid=TOWUBXV7K99X&qid=1739436798&rnid=29590822031&sprefix=%2Caps%2C488&xpid=qldnkxR_MsfSR&ref=sr_pg_15\n",
      "Page 16 scraped. Extracted 39 items.\n",
      "Scraping page 17: https://www.amazon.in/s?k=industrial+gloves&i=industrial&rh=n%3A5866078031%2Cp_n_feature_browse-bin%3A29591503031%257C29591523031&dc&page=17&crid=TOWUBXV7K99X&qid=1739436817&rnid=29590822031&sprefix=%2Caps%2C488&xpid=qldnkxR_MsfSR&ref=sr_pg_16\n",
      "Page 17 scraped. Extracted 41 items.\n",
      "Scraping page 18: https://www.amazon.in/s?k=industrial+gloves&i=industrial&rh=n%3A5866078031%2Cp_n_feature_browse-bin%3A29591503031%257C29591523031&dc&page=18&crid=TOWUBXV7K99X&qid=1739436832&rnid=29590822031&sprefix=%2Caps%2C488&xpid=qldnkxR_MsfSR&ref=sr_pg_17\n",
      "Page 18 scraped. Extracted 34 items.\n",
      "No more pages found or failed to click Next.\n",
      "Scraping completed and data saved.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Setup Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-notifications\")\n",
    "chrome_options.add_argument(\"--start-maximized\")\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (optional)\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "# Initialize WebDriver\n",
    "website = 'https://www.amazon.in/s?k=industrial+gloves&i=industrial&rh=n%3A5866078031%2Cp_n_feature_browse-bin%3A29591503031%257C29591523031&dc&crid=TOWUBXV7K99X&qid=1739436234&rnid=29590822031&sprefix=%2Caps%2C488&ref=sr_nr_p_n_feature_browse-bin_3&ds=v1%3AVxikSOEHytC6LBNN3kB7BkNR8Yz9sf7tUHWxDqvsMF0'\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.get(website)\n",
    "\n",
    "# Random delay to prevent bot detection\n",
    "time.sleep(random.randint(5, 10))\n",
    "\n",
    "# Check if page opened successfully\n",
    "print(f\"Scraping started: {driver.title}\")\n",
    "\n",
    "# Lists to store extracted data\n",
    "product_name = []\n",
    "product_price = []\n",
    "product_ratings = []\n",
    "product_ratings_num = []\n",
    "product_bought = []\n",
    "\n",
    "# Pagination loop\n",
    "page_number = 1\n",
    "max_pages = 53 # Change this to 160 if needed\n",
    "\n",
    "while page_number <= max_pages:\n",
    "    try:\n",
    "        print(f\"Scraping page {page_number}: {driver.current_url}\")\n",
    "\n",
    "        # Scroll down to load all elements\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(random.uniform(3, 6))\n",
    "\n",
    "        # Wait for product items to load\n",
    "        items = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, './/div[contains(@class,\"s-main-slot\")]/div'))\n",
    "        )\n",
    "\n",
    "        for item in items:\n",
    "            try:\n",
    "                name = item.find_element(By.XPATH, './/div[contains(@data-cy, \"title-recipe\")]').text\n",
    "                product_name.append(name)\n",
    "            except NoSuchElementException:\n",
    "                product_name.append(\"N/A\")\n",
    "\n",
    "            try:\n",
    "                price = item.find_element(By.XPATH, './/span[@class=\"a-price-whole\"]').text\n",
    "                product_price.append(price)\n",
    "            except NoSuchElementException:\n",
    "                product_price.append(\"N/A\")\n",
    "\n",
    "            try:\n",
    "                ratings = item.find_element(By.XPATH, './/span[@class=\"a-icon-alt\"]').text\n",
    "                product_ratings.append(ratings)\n",
    "            except NoSuchElementException:\n",
    "                product_ratings.append(\"N/A\")\n",
    "\n",
    "            try:\n",
    "                ratings_num = item.find_element(By.XPATH, './/span[@class=\"a-size-base s-underline-text\"]').text\n",
    "                product_ratings_num.append(ratings_num)\n",
    "            except NoSuchElementException:\n",
    "                product_ratings_num.append(\"N/A\")\n",
    "\n",
    "            try:\n",
    "                bought = item.find_element(By.XPATH, './/span[contains(text(),\"bought\") or contains(text(),\"sold\")]').text\n",
    "                product_bought.append(bought)\n",
    "            except NoSuchElementException:\n",
    "                product_bought.append(\"N/A\")\n",
    "\n",
    "        print(f\"Page {page_number} scraped. Extracted {len(items)} items.\")\n",
    "\n",
    "        # Check for \"Next\" button\n",
    "        try:\n",
    "            next_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, '//a[contains(@class, \"s-pagination-next\")]'))\n",
    "            )\n",
    "            next_button.click()\n",
    "            page_number += 1\n",
    "            time.sleep(random.uniform(5, 10))  # Allow time for next page to load\n",
    "        except (TimeoutException, NoSuchElementException):\n",
    "            print(\"No more pages found or failed to click Next.\")\n",
    "            break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error on page {page_number}: {e}\")\n",
    "        break\n",
    "\n",
    "# Creating DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'product_name': product_name,\n",
    "    'product_price': product_price,\n",
    "    'product_ratings': product_ratings,\n",
    "    'product_ratings_num': product_ratings_num,\n",
    "    'product_bought': product_bought\n",
    "})\n",
    "\n",
    "# Save to Excel\n",
    "df.to_excel('amazon_india_chemical_resistant_gloves.xlsx', index=False)\n",
    "\n",
    "# Close WebDriver\n",
    "driver.quit()\n",
    "\n",
    "print(\"Scraping completed and data saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe1f6f4c-d3e6-43f4-9a34-36e847aa5480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_price</th>\n",
       "      <th>product_ratings</th>\n",
       "      <th>product_ratings_num</th>\n",
       "      <th>product_bought</th>\n",
       "      <th>product_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sponsored\\nRobustt Nylon Nitrile Half Coated (...</td>\n",
       "      <td>349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cut resistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sponsored\\nRobustt Nylon Nitrile Coated Indust...</td>\n",
       "      <td>479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cut resistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sponsored\\nSR TRENDS Nitrile Coated Safety Glo...</td>\n",
       "      <td>332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cut resistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nylon Industrial &amp; Home Safety Cut Resistant H...</td>\n",
       "      <td>419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50+ bought in past month</td>\n",
       "      <td>cut resistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Karomouj Karo-988S Anti Cut Resistant Level 5 ...</td>\n",
       "      <td>279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2,375</td>\n",
       "      <td>1K+ bought in past month</td>\n",
       "      <td>cut resistant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        product_name product_price  \\\n",
       "0  Sponsored\\nRobustt Nylon Nitrile Half Coated (...           349   \n",
       "1  Sponsored\\nRobustt Nylon Nitrile Coated Indust...           479   \n",
       "2  Sponsored\\nSR TRENDS Nitrile Coated Safety Glo...           332   \n",
       "3  Nylon Industrial & Home Safety Cut Resistant H...           419   \n",
       "4  Karomouj Karo-988S Anti Cut Resistant Level 5 ...           279   \n",
       "\n",
       "   product_ratings product_ratings_num            product_bought  \\\n",
       "0              NaN                 149                       NaN   \n",
       "1              NaN                 412                       NaN   \n",
       "2              NaN                  32                       NaN   \n",
       "3              NaN                 NaN  50+ bought in past month   \n",
       "4              NaN               2,375  1K+ bought in past month   \n",
       "\n",
       "    product_type  \n",
       "0  cut resistant  \n",
       "1  cut resistant  \n",
       "2  cut resistant  \n",
       "3  cut resistant  \n",
       "4  cut resistant  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Code to remove NA in all rows\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "file_name=\"amazon_india_gloves_cut_resistant\"\n",
    "cur_dir = os.getcwd()\n",
    "curr_dir=os.chdir('C:\\\\Users\\\\Wishes Lawrence\\\\Desktop\\\\lace-data1\\\\Desktop\\\\Gloves_data')\n",
    "full_path=os.path.join(cur_dir,file_name)\n",
    "full_path\n",
    "\n",
    "df=pd.read_excel(full_path+\".xlsx\")\n",
    "df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2a86734-018e-4389-b413-ad853eb57977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Sponsored Robustt\n",
       "1      Sponsored Robustt\n",
       "2           Sponsored SR\n",
       "3       Nylon Industrial\n",
       "4          Karomouj Karo\n",
       "             ...        \n",
       "903     Sponsored VALPRO\n",
       "904       Sponsored UREC\n",
       "905         Sponsored RK\n",
       "906         Sponsored RK\n",
       "907    Sponsored F8WARES\n",
       "Name: brand, Length: 908, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['brand'] = df['product_name'].str.extract(r'(\\w+\\s\\w+)')\n",
    "df['brand'] = df['brand'].str.replace('\\n', ' ', regex=True)\n",
    "df['Ttpe ']\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d56dfe3b-bebe-4fdd-bedf-c21b15960fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           Nylon Nitrile Half\n",
       "1         Nylon Nitrile Coated\n",
       "2        TRENDS Nitrile Coated\n",
       "3           Cut Resistant Hand\n",
       "4          Cut Resistant Level\n",
       "                ...           \n",
       "903      Techtion Reusable and\n",
       "904    Industrial Safety Nylon\n",
       "905      TRENDS Nitrile Coated\n",
       "906       Trends Safety Gloves\n",
       "907                1PK 14 Inch\n",
       "Name: Coating, Length: 908, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Coating'] = df['product_name'].str.extract(r'(?:\\w+\\s\\w+)\\s(\\w+\\s\\w+\\s\\w+)')\n",
    "df['Coating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06bc664a-78aa-4d75-a243-35426b88fbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_price</th>\n",
       "      <th>product_ratings</th>\n",
       "      <th>product_ratings_num</th>\n",
       "      <th>product_bought</th>\n",
       "      <th>product_type</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sponsored\\nRobustt Nylon Nitrile Half Coated (...</td>\n",
       "      <td>349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cut resistant</td>\n",
       "      <td>Sponsored\\nRobustt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sponsored\\nRobustt Nylon Nitrile Coated Indust...</td>\n",
       "      <td>479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cut resistant</td>\n",
       "      <td>Sponsored\\nRobustt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sponsored\\nSR TRENDS Nitrile Coated Safety Glo...</td>\n",
       "      <td>332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cut resistant</td>\n",
       "      <td>Sponsored\\nSR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nylon Industrial &amp; Home Safety Cut Resistant H...</td>\n",
       "      <td>419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50+ bought in past month</td>\n",
       "      <td>cut resistant</td>\n",
       "      <td>Nylon Industrial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Karomouj Karo-988S Anti Cut Resistant Level 5 ...</td>\n",
       "      <td>279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2,375</td>\n",
       "      <td>1K+ bought in past month</td>\n",
       "      <td>cut resistant</td>\n",
       "      <td>Karomouj Karo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>Sponsored\\nVALPRO Techtion Reusable and Washab...</td>\n",
       "      <td>207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cut resistant</td>\n",
       "      <td>Sponsored\\nVALPRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>Sponsored\\nUREC-Heavy Duty Industrial Safety N...</td>\n",
       "      <td>349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cut resistant</td>\n",
       "      <td>Sponsored\\nUREC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>Sponsored\\nRK TRENDS Nitrile Coated Safety Glo...</td>\n",
       "      <td>1,829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cut resistant</td>\n",
       "      <td>Sponsored\\nRK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>Sponsored\\nRK Trends Safety Gloves - Heavy Dut...</td>\n",
       "      <td>340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cut resistant</td>\n",
       "      <td>Sponsored\\nRK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>Sponsored\\nF8WARES 1PK 14 Inch Thick &amp; Heavy D...</td>\n",
       "      <td>298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>239</td>\n",
       "      <td>300+ bought in past month</td>\n",
       "      <td>cut resistant</td>\n",
       "      <td>Sponsored\\nF8WARES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>908 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          product_name product_price  \\\n",
       "0    Sponsored\\nRobustt Nylon Nitrile Half Coated (...           349   \n",
       "1    Sponsored\\nRobustt Nylon Nitrile Coated Indust...           479   \n",
       "2    Sponsored\\nSR TRENDS Nitrile Coated Safety Glo...           332   \n",
       "3    Nylon Industrial & Home Safety Cut Resistant H...           419   \n",
       "4    Karomouj Karo-988S Anti Cut Resistant Level 5 ...           279   \n",
       "..                                                 ...           ...   \n",
       "903  Sponsored\\nVALPRO Techtion Reusable and Washab...           207   \n",
       "904  Sponsored\\nUREC-Heavy Duty Industrial Safety N...           349   \n",
       "905  Sponsored\\nRK TRENDS Nitrile Coated Safety Glo...         1,829   \n",
       "906  Sponsored\\nRK Trends Safety Gloves - Heavy Dut...           340   \n",
       "907  Sponsored\\nF8WARES 1PK 14 Inch Thick & Heavy D...           298   \n",
       "\n",
       "     product_ratings product_ratings_num             product_bought  \\\n",
       "0                NaN                 149                        NaN   \n",
       "1                NaN                 412                        NaN   \n",
       "2                NaN                  32                        NaN   \n",
       "3                NaN                 NaN   50+ bought in past month   \n",
       "4                NaN               2,375   1K+ bought in past month   \n",
       "..               ...                 ...                        ...   \n",
       "903              NaN                  26                        NaN   \n",
       "904              NaN                   1                        NaN   \n",
       "905              NaN                 NaN                        NaN   \n",
       "906              NaN                 NaN                        NaN   \n",
       "907              NaN                 239  300+ bought in past month   \n",
       "\n",
       "      product_type               brand  \n",
       "0    cut resistant  Sponsored\\nRobustt  \n",
       "1    cut resistant  Sponsored\\nRobustt  \n",
       "2    cut resistant       Sponsored\\nSR  \n",
       "3    cut resistant    Nylon Industrial  \n",
       "4    cut resistant       Karomouj Karo  \n",
       "..             ...                 ...  \n",
       "903  cut resistant   Sponsored\\nVALPRO  \n",
       "904  cut resistant     Sponsored\\nUREC  \n",
       "905  cut resistant       Sponsored\\nRK  \n",
       "906  cut resistant       Sponsored\\nRK  \n",
       "907  cut resistant  Sponsored\\nF8WARES  \n",
       "\n",
       "[908 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ed81486-bbf2-49c8-b267-6847d5b0f957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in c:\\users\\wishes lawrence\\anaconda3\\lib\\site-packages (2.0.37)\n",
      "Requirement already satisfied: psycopg2-binary in c:\\users\\wishes lawrence\\anaconda3\\lib\\site-packages (2.9.10)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\wishes lawrence\\anaconda3\\lib\\site-packages (from sqlalchemy) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\wishes lawrence\\anaconda3\\lib\\site-packages (from sqlalchemy) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sqlalchemy psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b154b7a8-d177-46b3-b5cb-4a52fbb7b207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "432b5606-4d8b-4e34-8122-56891ae45980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c07db1a4-eac4-4dce-a934-45f42d3b5f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create the engine object (do this ONCE):\n",
    "connection_string = \"postgresql://root:root@localhost:5432/postgres\" # Your connection string\n",
    "engine = create_engine(connection_string)  # Create the engine object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66f14e31-676c-4036-a8d5-8dfd20ab55d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.base.Connection at 0x23b8625a710>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746f4fcf-ab5d-48da-9e1c-00118608b115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68e2c853-f331-4dd3-b7be-ad710be23ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "908"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_sql(name='amazon_india_gloves_cut_resistant',con=engine,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c1dea6b-869b-4a5c-a146-da8d5fd50931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE amazon_india_gloves_cut_resistant (\n",
      "\tproduct_name TEXT, \n",
      "\tproduct_price TEXT, \n",
      "\tproduct_ratings FLOAT(53), \n",
      "\tproduct_ratings_num TEXT, \n",
      "\tproduct_bought TEXT, \n",
      "\tproduct_type TEXT\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.io.sql.get_schema(df,name='amazon_india_gloves_cut_resistant',con=engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43452ee8-12ec-47d1-83c3-94ab683593ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize=100\n",
    "# Process the DataFrame in chunks\n",
    "for i in range(0, len(df), chunksize):\n",
    "    chunk = df.iloc[i:i + chunksize]  # Extract chunk\n",
    "    try:\n",
    "        # Write the chunk to PostgreSQL\n",
    "        chunk.to_sql('amazon_india_gloves_cut_resistant', con=engine, if_exists='append', index=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing chunk {i//chunksize + 1}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25d6a5bf-1758-4c78-bc31-c50cb465850b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "908"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_sql(name='amazon_india_gloves_cut_resistant', con=engine, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48558685-016b-4920-9e69-bc83c60cdb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Inserted chunk 1\n",
      "âœ… Inserted chunk 2\n",
      "âœ… Inserted chunk 3\n",
      "âœ… Inserted chunk 4\n",
      "âœ… Inserted chunk 5\n",
      "âœ… Inserted chunk 6\n",
      "âœ… Inserted chunk 7\n",
      "âœ… Inserted chunk 8\n",
      "âœ… Inserted chunk 9\n",
      "âœ… Inserted chunk 10\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Database connection\n",
    "connection_string = \"postgresql://kestra:k3str4@localhost:5432/postgres\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Ensure table exists before appending\n",
    "df.iloc[:1].to_sql('amazon_india_gloves_cut_resistant', con=engine, if_exists='append', index=False)\n",
    "\n",
    "chunksize = 100\n",
    "for i in range(0, len(df), chunksize):\n",
    "    chunk = df.iloc[i:i + chunksize]  \n",
    "    try:\n",
    "        chunk.to_sql('amazon_india_gloves_cut_resistant', con=engine, if_exists='append', index=False)\n",
    "        print(f\"âœ… Inserted chunk {i//chunksize + 1}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error inserting chunk {i//chunksize + 1}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9c4f09-17dc-47c9-a2dc-7413cda5e3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Setup Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-notifications\")\n",
    "chrome_options.add_argument(\"--start-maximized\")\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (optional)\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "# Initialize WebDriver\n",
    "website = 'https://www.amazon.in/s?k=industrial+gloves&i=industrial&rh=n%3A5866078031%2Cp_n_feature_browse-bin%3A29591503031%257C29591523031&dc&crid=TOWUBXV7K99X&qid=1739436234&rnid=29590822031&sprefix=%2Caps%2C488&ref=sr_nr_p_n_feature_browse-bin_3&ds=v1%3AVxikSOEHytC6LBNN3kB7BkNR8Yz9sf7tUHWxDqvsMF0'\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.get(website)\n",
    "\n",
    "# Random delay to prevent bot detection\n",
    "time.sleep(random.randint(5, 10))\n",
    "\n",
    "# Check if page opened successfully\n",
    "print(f\"Scraping started: {driver.title}\")\n",
    "\n",
    "# Lists to store extracted data\n",
    "product_name = []\n",
    "product_price = []\n",
    "product_ratings = []\n",
    "product_ratings_num = []\n",
    "product_bought = []\n",
    "\n",
    "# Pagination loop\n",
    "page_number = 1\n",
    "max_pages = 53 # Change this to 160 if needed\n",
    "\n",
    "while page_number <= max_pages:\n",
    "    try:\n",
    "        print(f\"Scraping page {page_number}: {driver.current_url}\")\n",
    "\n",
    "        # Scroll down to load all elements\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(random.uniform(3, 6))\n",
    "\n",
    "        # Wait for product items to load\n",
    "        items = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, './/div[contains(@class,\"s-main-slot\")]/div'))\n",
    "        )\n",
    "\n",
    "        for item in items:\n",
    "            try:\n",
    "                name = item.find_element(By.XPATH, './/div[contains(@data-cy, \"title-recipe\")]').text\n",
    "                product_name.append(name)\n",
    "            except NoSuchElementException:\n",
    "                product_name.append(\"N/A\")\n",
    "\n",
    "            try:\n",
    "                price = item.find_element(By.XPATH, './/span[@class=\"a-price-whole\"]').text\n",
    "                product_price.append(price)\n",
    "            except NoSuchElementException:\n",
    "                product_price.append(\"N/A\")\n",
    "\n",
    "            try:\n",
    "                ratings = item.find_element(By.XPATH, './/span[@class=\"a-icon-alt\"]').text\n",
    "                product_ratings.append(ratings)\n",
    "            except NoSuchElementException:\n",
    "                product_ratings.append(\"N/A\")\n",
    "\n",
    "            try:\n",
    "                ratings_num = item.find_element(By.XPATH, './/span[@class=\"a-size-base s-underline-text\"]').text\n",
    "                product_ratings_num.append(ratings_num)\n",
    "            except NoSuchElementException:\n",
    "                product_ratings_num.append(\"N/A\")\n",
    "\n",
    "            try:\n",
    "                bought = item.find_element(By.XPATH, './/span[contains(text(),\"bought\") or contains(text(),\"sold\")]').text\n",
    "                product_bought.append(bought)\n",
    "            except NoSuchElementException:\n",
    "                product_bought.append(\"N/A\")\n",
    "\n",
    "        print(f\"Page {page_number} scraped. Extracted {len(items)} items.\")\n",
    "\n",
    "        # Check for \"Next\" button\n",
    "        try:\n",
    "            next_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, '//a[contains(@class, \"s-pagination-next\")]'))\n",
    "            )\n",
    "            next_button.click()\n",
    "            page_number += 1\n",
    "            time.sleep(random.uniform(5, 10))  # Allow time for next page to load\n",
    "        except (TimeoutException, NoSuchElementException):\n",
    "            print(\"No more pages found or failed to click Next.\")\n",
    "            break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error on page {page_number}: {e}\")\n",
    "        break\n",
    "\n",
    "# Creating DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'product_name': product_name,\n",
    "    'product_price': product_price,\n",
    "    'product_ratings': product_ratings,\n",
    "    'product_ratings_num': product_ratings_num,\n",
    "    'product_bought': product_bought\n",
    "})\n",
    "\n",
    "# Save to Excel\n",
    "df.to_excel('amazon_india_chemical_resistant_gloves.xlsx', index=False)\n",
    "\n",
    "# Close WebDriver\n",
    "driver.quit()\n",
    "\n",
    "print(\"Scraping completed and data saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58ab1d9-a631-4668-a59e-c96698a700b1",
   "metadata": {},
   "source": [
    "# Scrapping of Indian Amazon website with all features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda93ac3-9daa-4cde-abba-ca769c637e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping started: Amazon.in : industrial gloves\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Setup Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-notifications\")\n",
    "chrome_options.add_argument(\"--start-maximized\")\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (optional)\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "# Initialize WebDriver\n",
    "website = 'https://www.amazon.in/s?k=industrial+gloves&i=industrial&rh=n%3A5866078031%2Cp_n_feature_browse-bin%3A29591503031%257C29591523031&dc&crid=TOWUBXV7K99X&qid=1739436234&rnid=29590822031&sprefix=%2Caps%2C488&ref=sr_nr_p_n_feature_browse-bin_3&ds=v1%3AVxikSOEHytC6LBNN3kB7BkNR8Yz9sf7tUHWxDqvsMF0'\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.get(website)\n",
    "\n",
    "# Random delay to prevent bot detection\n",
    "time.sleep(random.randint(5, 10))\n",
    "\n",
    "\n",
    "# Check if page opened successfully\n",
    "print(f\"Scraping started: {driver.title}\")\n",
    "\n",
    "# Lists to store extracted data\n",
    "product_name = []\n",
    "product_price = []\n",
    "product_ratings = []\n",
    "product_ratings_num = []\n",
    "product_bought = []\n",
    "product_material=[]\n",
    "product_brand=[]\n",
    "# Step1 get the links for the products on the page\n",
    "product_links=WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.XPATH,'//a[@class=\"a-link-normal s-line-clamp-4 s-link-style a-text-normal\"]')))\n",
    "for product in product_links:\n",
    "    product_url=product.get_attribute('href')\n",
    "    for url in product_url:\n",
    "        try:\n",
    "            ratings=WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH,'//i[@class=\"a-icon a-icon-star a-star-3-5 cm-cr-review-stars-spacing-big\"]')))\n",
    "            product_ratings.append(ratings.text)\n",
    "            print(product_ratings)\n",
    "        except:\n",
    "            product_ratings.append(\"NA\")\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5caad79-6bc4-4e2a-92f8-256c3f9b6b97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572845de-98d4-4e7a-b65f-210837c7d606",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
